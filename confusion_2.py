# -*- coding: utf-8 -*-
"""Confusion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jbs-xcB4Tcni0HiC-OBisVZDD1qyuGqK
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix

iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)

clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

cm = confusion_matrix(y_test, y_pred)

labels = ["Setosa","Versicolor","Virginica"]
df_cm = pd.DataFrame(cm, index=labels, columns=labels)
plt.figure(figsize=(8,6))
sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification

X,y = make_classification(n_samples=1000, n_classes=2, random_state=42)

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=120)

clf = LogisticRegression()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

cm = confusion_matrix(y_test,y_pred)

tn,fp,fn,tp = cm.ravel()
precision = tp/(tp+tp)
recall = tp/(tp+fn)
f1_score = 2*(precision*recall)/(precision + recall)
accuracy = (tp+tn) / (tp+tn+fp+fn)

plt.figure(figsize=(8,6))
plt.imshow(cm, cmap="Blues", interpolation="nearest")
plt.title("Confusion Matrix")
plt.colorbar()
tick_marks = np.arange(2)
plt.xticks(tick_marks, ["Negative", "Positive"],rotation=45)
plt.yticks(tick_marks, ["Negative", "Positive"])
plt.xlabel('Predicted')
plt.ylabel('Actual')

plt.text(0,0, f"True Negative: {tn}", ha="center",va="center",color="white", fontsize=12)
plt.text(0,1, f"False Negative: {fn}", ha="center",va="center",color="black", fontsize=12)
plt.text(1,0, f"False Negative: {fp}", ha="center",va="center",color="black", fontsize=12)
plt.text(1,1, f"True Negative: {tp}", ha="center",va="center",color="white", fontsize=12)

plt.text(2.5,0, f"Precision: {precision:.2f}", ha="center",va="center",color="black", fontsize=12)
plt.text(2.5,-0.2, f"Recall: {recall:.2f}", ha="center",va="center",color="black", fontsize=12)
plt.text(2.5,-0.4, f"F1 Score: {f1_score:.2f}", ha="center",va="center",color="black", fontsize=12)
plt.text(2.5,-0.6, f"Accuracy: {accuracy:.2f}", ha="center",va="center",color="black", fontsize=12)
plt.show()